{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the % returns in 15 min and 75 min period for NIFTY futures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Dev Plan :: #\n",
    "\n",
    "# Load all futures data in a single dataframe file by file\n",
    "# There may be some data points where volume is low or those futures are little ahead of the time, it is better to eliminate those.\n",
    "# Then create a series of 15 min/75 min return in percent\n",
    "# It is better to create a series on range of the candle in percent as well\n",
    "# Plot typical returns over entire data (2 years -2019 -2020)\n",
    "# Plot typical returns month\n",
    "# Plot cummulative % return of the period\n",
    "\n",
    "#Why I am plotting this?\n",
    "# 1. Typical return gives idea how much I'll make/loose on the trade x% of time ~ 75% time\n",
    "# 2. Is range significantly different for returns ~ This may translate in hitting stops or targets.\n",
    "# 3. Typicall mean reversion behaviour ~ how much cummulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import logging\n",
    "from typing import Dict\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging (Requires restart for log level change)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logger = logging.getLogger('LOGGER_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test settings\n",
    "\n",
    "runtests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Folders\n",
    "\n",
    "DATA_DIR = './../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Statics\n",
    "\n",
    "COLUMN_NAMES = ['Instrument', 'Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Open Interest']\n",
    "OHLC_CONVERSION_DICT: Dict[str, str] = {'Instrument' : 'first',\n",
    "                                        'Open': 'first',\n",
    "                                        'High': 'max',\n",
    "                                        'Low': 'min',\n",
    "                                        'Close': 'last',\n",
    "                                        'Volume': 'sum',\n",
    "                                        'Open Interest': 'last'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for loading fut file in to a dataframe\n",
    "\n",
    "def load_data(csv_file_path : str) -> pd.DataFrame:\n",
    "    data = pd.read_csv(csv_file_path, header=None, index_col=None,\n",
    "                                      names=COLUMN_NAMES,\n",
    "                                      parse_dates=[['Date', 'Time']])\n",
    "    data.set_index('Date_Time', inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:LOGGER_NAME:['./../data/NIFTY19MARFUT.csv', './../data/NIFTY19SEPFUT.csv', './../data/NIFTY19JANFUT.csv']\n"
     ]
    }
   ],
   "source": [
    "# Load data files in a list\n",
    "\n",
    "data_file_path_list = []\n",
    "for name in glob.glob(DATA_DIR+'NIFTY[0-9]*FUT.csv'):\n",
    "    data_file_path_list.append(name)\n",
    "\n",
    "logger.debug(data_file_path_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a 1 min data to 15 min Candle\n",
    "\n",
    "def aggregate_to_15Min(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    min15_data = data.resample('15min', origin='start').agg(OHLC_CONVERSION_DICT)\n",
    "    return min15_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a 1 min data to 75 min Candle\n",
    "\n",
    "def aggregate_to_75min(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    min15_data = aggregate_to_15Min(data)\n",
    "    index_dates = pd.Series(np.unique(min15_data.index.date))\n",
    "    list_of_min75_data_by_date = []\n",
    "    for idx_date in index_dates:\n",
    "        idx_date_str = idx_date.strftime(format='%Y-%m-%d')\n",
    "        min75_data_by_date = min15_data[idx_date_str].resample('75Min', origin='start').agg(OHLC_CONVERSION_DICT)\n",
    "        list_of_min75_data_by_date.append(min75_data_by_date)\n",
    "\n",
    "    min75_data = pd.concat(list_of_min75_data_by_date)\n",
    "    return min75_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent return for n period\n",
    "\n",
    "def calculate_pct_returns(price_series : pd.Series, n : int) -> pd.Series:\n",
    "    n_returns = (price_series/price_series.shift(n) - 1)*100\n",
    "    n_returns = n_returns.dropna()\n",
    "    return n_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:LOGGER_NAME:Total number of series : 21\n",
      "DEBUG:LOGGER_NAME:Total number of returns : 25668\n"
     ]
    }
   ],
   "source": [
    "# Create 15 min dataframes and combine across all future data files\n",
    "\n",
    "pct_returns_15min_temp = [calculate_pct_returns(aggregate_to_15Min(load_data(csv_file_path= file_path))['Close'], n=1).values for file_path in data_file_path_list]\n",
    "pct_returns_15min = [ret for series_ret in pct_returns_15min_temp for ret in series_ret]\n",
    "logger.debug('Total number of series : %d' % len(pct_returns_15min_temp))\n",
    "logger.debug('Total number of returns : %d' % len(pct_returns_15min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1460,\n",
       " 1430,\n",
       " 552,\n",
       " 528,\n",
       " 1032,\n",
       " 1367,\n",
       " 1392,\n",
       " 1491,\n",
       " 1400,\n",
       " 48,\n",
       " 1383,\n",
       " 1389,\n",
       " 1294,\n",
       " 1499,\n",
       " 1452,\n",
       " 1316,\n",
       " 1484,\n",
       " 1269,\n",
       " 1508,\n",
       " 1415,\n",
       " 959]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in pct_returns_15min_temp] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_aggregate_to_15Min (__main__.TestNotebook) ... ok\n",
      "test_aggregate_to_75min (__main__.TestNotebook) ... ok\n",
      "test_calculate_pct_returns_period_1 (__main__.TestNotebook) ... ok\n",
      "test_load_data (__main__.TestNotebook) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.663s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    \n",
    "    test_csv_file_path = './../data/NIFTY19MARFUT.csv'\n",
    "    \n",
    "    # test load data function for a single file\n",
    "    def test_load_data(self):\n",
    "        self.assertEqual(len(load_data(csv_file_path=self.test_csv_file_path)), 19773)\n",
    "        \n",
    "    def test_aggregate_to_15Min(self):\n",
    "        data = load_data(csv_file_path=self.test_csv_file_path)\n",
    "        data_15min = aggregate_to_15Min(data)\n",
    "        self.assertEqual(len(data_15min), 8281)\n",
    "        \n",
    "    def test_aggregate_to_75min(self):\n",
    "        data = load_data(csv_file_path=self.test_csv_file_path)\n",
    "        data_75min = aggregate_to_75min(data)\n",
    "        self.assertEqual(len(data_75min), 1725)\n",
    "        \n",
    "    def test_calculate_pct_returns_period_1(self):\n",
    "        series = pd.Series([100.0,101.0,101.55])\n",
    "        returns = calculate_pct_returns(series, n=1)\n",
    "        self.assertAlmostEqual(returns.iloc[0], 1.0)\n",
    "\n",
    "if runtests:\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
